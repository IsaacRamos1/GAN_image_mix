{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Mix_Styles.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNIa365YphFfHWyyj/1iYHO"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"H1vAXQpeFRqb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594687897861,"user_tz":180,"elapsed":2235,"user":{"displayName":"Isaac Ramos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gje5X-RzoqFglwaQNenWr2c-pgJ32bq5-Uv4Y9DXA=s64","userId":"05115599965143899417"}},"outputId":"f12a06f9-84f5-4585-f141-3f3f8711a913"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"757UaNByFu7A","colab_type":"code","colab":{}},"source":["import PIL.Image\n","from keras.preprocessing.image import load_img, save_img, img_to_array\n","import numpy as np\n","from scipy.optimize import fmin_l_bfgs_b, minimize\n","import time\n","from keras.applications import vgg19\n","from keras import backend as K"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3GpYw7eepGv-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594687898854,"user_tz":180,"elapsed":3109,"user":{"displayName":"Isaac Ramos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gje5X-RzoqFglwaQNenWr2c-pgJ32bq5-Uv4Y9DXA=s64","userId":"05115599965143899417"}},"outputId":"e185cd80-c56d-40e5-c749-b4eaab3438e2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ia_WyWPVGCaG","colab_type":"code","colab":{}},"source":["base_image_path = '/content/drive/My Drive/Colab Notebooks/Foto.jpg'\n","style_reference_image_path = '/content/drive/My Drive/Colab Notebooks/anime-boy.jpg' \n","\n","iterations = 8\n","\n","# these are the weights of the different loss components\n","total_variation_weight = 1.0\n","style_weight = 1.2\n","content_weight = 0.025\n","\n","# dimensions of the generated picture.\n","width, height = load_img(base_image_path).size\n","img_nrows = 720\n","img_ncols = int(width * img_nrows / height)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3SNyjNilGJMu","colab_type":"code","colab":{}},"source":["def preprocess_image(image_path):\n","    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n","    img = img_to_array(img)\n","    img = np.expand_dims(img, axis=0)\n","    img = vgg19.preprocess_input(img)\n","    return img\n","\n","# util function to convert a tensor into a valid image\n","def deprocess_image(x):\n","    if K.image_data_format() == 'channels_first':\n","        x = x.reshape((3, img_nrows, img_ncols))\n","        x = x.transpose((1, 2, 0))\n","    else:\n","        x = x.reshape((img_nrows, img_ncols, 3))\n","    # Remove zero-center by mean pixel\n","    x[:, :, 0] += 103.939\n","    x[:, :, 1] += 116.779\n","    x[:, :, 2] += 123.68\n","    # 'BGR'->'RGB'\n","    x = x[:, :, ::-1]\n","    x = np.clip(x, 0, 255).astype('uint8')\n","    return x\n","\n","  # the gram matrix of an image tensor (feature-wise outer product)\n","\n","\n","def gram_matrix(x):\n","    assert K.ndim(x) == 3\n","    if K.image_data_format() == 'channels_first':\n","        features = K.batch_flatten(x)\n","    else:\n","        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n","    gram = K.dot(features, K.transpose(features))\n","    return gram\n","\n","# the \"style loss\" is designed to maintain\n","# the style of the reference image in the generated image.\n","\n","def style_loss(style, combination):\n","    assert K.ndim(style) == 3\n","    assert K.ndim(combination) == 3\n","    S = gram_matrix(style)\n","    C = gram_matrix(combination)\n","    channels = 3\n","    size = img_nrows * img_ncols\n","    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n","\n","def content_loss(base, combination):\n","    return K.sum(K.square(combination - base))\n","\n","def total_variation_loss(x):\n","    assert K.ndim(x) == 4\n","    if K.image_data_format() == 'channels_first':\n","        a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])\n","        b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, :img_nrows - 1, 1:])\n","    else:\n","        a = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n","        b = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n","    return K.sum(K.pow(a + b, 1.25))\n","\n","def eval_loss_and_grads(x):\n","    if K.image_data_format() == 'channels_first':\n","        x = x.reshape((1, 3, img_nrows, img_ncols))\n","    else:\n","        x = x.reshape((1, img_nrows, img_ncols, 3))\n","\t\t# f_outputs is defined below\n","    outs = f_outputs([x])\n","    loss_value = outs[0]\n","    if len(outs[1:]) == 1:\n","        grad_values = outs[1].flatten().astype('float64')\n","    else:\n","        grad_values = np.array(outs[1:]).flatten().astype('float64')\n","    return loss_value, grad_values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5fT7fKDGTve","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594687900978,"user_tz":180,"elapsed":5160,"user":{"displayName":"Isaac Ramos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gje5X-RzoqFglwaQNenWr2c-pgJ32bq5-Uv4Y9DXA=s64","userId":"05115599965143899417"}},"outputId":"dbf1f89a-3e21-4d7b-bb30-a8cc966af7cb"},"source":["# get tensor representations of our images\n","base_image = K.variable(preprocess_image(base_image_path))\n","\n","style_reference_image = K.variable(preprocess_image(style_reference_image_path))\n","\n","# this will contain our generated image\n","print(K.image_data_format())\n","\n","if K.image_data_format() == 'channels_first':\n","    combination_image = K.placeholder((1, 3, img_nrows, img_ncols))\n","else:\n","    combination_image = K.placeholder((1, img_nrows, img_ncols, 3))\n","\n","# combine the 3 images into a single Keras tensor\n","input_tensor = K.concatenate([base_image,\n","                              style_reference_image,\n","                              combination_image], axis=0)\n","\n","model = vgg19.VGG19(input_tensor=input_tensor,\n","                    weights='imagenet', include_top=False)\n","\n","print('Model loaded.')\n","\n","outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n","\n","\n","# combine loss functions into a single scalar\n","loss = K.variable(0.)\n","layer_features = outputs_dict['block5_conv2']\n","base_image_features = layer_features[0, :, :, :]\n","combination_features = layer_features[2, :, :, :]\n","loss = loss + content_weight * content_loss(base_image_features,\n","                                      combination_features)\n","\n","# layers\n","feature_layers = ['block1_conv1', 'block2_conv1',\n","                  'block3_conv1', 'block4_conv1',\n","                  'block5_conv1']\n","\n","for layer_name in feature_layers:\n","    layer_features = outputs_dict[layer_name]\n","    style_reference_features = layer_features[1, :, :, :]\n","    combination_features = layer_features[2, :, :, :]\n","    sl = style_loss(style_reference_features, combination_features)\n","    loss = loss + (style_weight / len(feature_layers)) * sl\n","\n","loss = loss + total_variation_weight * total_variation_loss(combination_image)\n","\n","# get the gradients of the generated image wrt the loss\n","grads = K.gradients(loss, combination_image)\n","\n","outputs = [loss]\n","if isinstance(grads, (list, tuple)):\n","    outputs = outputs + grads\n","else:\n","    outputs.append(grads)\n","\n","f_outputs = K.function([combination_image], outputs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["channels_last\n","Model loaded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tf0ybUFXGnyt","colab_type":"code","colab":{}},"source":["class Evaluator(object):\n","\n","    def __init__(self):\n","        self.loss_value = None\n","        self.grads_values = None\n","\n","    def loss(self, x):\n","        assert self.loss_value is None\n","        loss_value, grad_values = eval_loss_and_grads(x)\n","        self.loss_value = loss_value\n","        self.grad_values = grad_values\n","        return self.loss_value\n","\n","    def grads(self, x):\n","        assert self.loss_value is not None\n","        grad_values = np.copy(self.grad_values)\n","        self.loss_value = None\n","        self.grad_values = None\n","        return grad_values\n","\n","evaluator = Evaluator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7-4VD31GpVN","colab_type":"code","colab":{}},"source":["x = preprocess_image(base_image_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yOGQw7vIGre2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c502ea67-21f2-4e42-c863-da20f520ad4d"},"source":["from google.colab import files\n","\n","for i in range(iterations):\n","    print('Start of iteration', i)\n","    start_time = time.time()\n","    \n","    # fmin_l_bfgs_b\n","    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, \n","                                     x.flatten(),\n","                                     fprime=evaluator.grads,\n","                                     maxfun=50)\n","\n","    print('Current loss value:', min_val)\n","    # save current generated image\n","    img = deprocess_image(x.copy())\n","\n","    fname = 'AnaPaula_it_%d.png' % i\n","    save_img(fname, img)\n","    #files.download(img)\n","    end_time = time.time()\n","    print('Image saved as', fname)\n","    print('Iteration %d completed in %ds' % (i, end_time - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Start of iteration 0\n"],"name":"stdout"}]}]}